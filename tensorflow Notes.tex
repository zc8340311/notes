\documentclass{article}
\usepackage{mathtools}
\begin{document}
\section{Basic Usage}
Tensorflow is a programming system in which you represent computation as graphs.\\
Nodes in the graph are called 'ops'. \\
An op takes zero or more tensors.
A tensor is a typed multidiemtnsional array. \\
A graph must be lauched in a Session. A session places methods to execute them (Cpu, Gpu). \\
These methods return tensors produced by ops as numpy ndarray objects in python.

\subsection{Tensors}
Tensorflow use a tensor data structure to represent all data- only tensors are pass ed between  operations in the comptuation graph.
A tensor has static type a rank and a shape. \\
A Tensor rank is not the same as matrix rank. Tensor rank  is the number of dimensions of the tensor. Rank 0 means Scalar, Rank 1 means vactor and rank 2 = matrix rank 3 = 3-Tensor (cube of numbers)
\subsection{Variables}
variables represent the state in computation grapgh and it won't be excuted/performed until the session run method.

\subsection{Fetches}
to fetch the output of operations execute the graph with a run() call on the Session object and pass in the tensors to retrive.
\subsection{Feeds}
Feeds is a mechanism for patching a tensor directly into any operation in the graph.
A feed temporarily replace the output of an operation with a tensor value. When call run(), you need to give its value as run ([output1, output2], {holdername1 : value1, holdername2 : value2})

\section{Problem Records}
\subsection{logloss in theano does not work on the tensorflow}
logloss $  \dfrac{1}{N}\sum_{N} \sum_{j} target * \log predict + (1 -target) * \log (1-predict) $ use log, when the predict close to 1 or close to 0 the result will will really large and return nan. Use other loss, like build-in log loss, but seem this loss can not give the a clear reconstruction. The reconstruction picture looks not very clear. 


(In my understanding, this log loss is the feature-wise loss, calculate the difference on each features the reduce to mean.)

\end{document}
